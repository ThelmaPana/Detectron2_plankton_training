{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Detectron2 training on plankton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "import lib.training_functions as training_functions # Custom training functions\n",
    "import lib.my_visualizer as my_visualizer #â€¯Custom Detectron2 visualizer to increase font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = 'output/output_*'\n",
    "output_dirs = glob.glob(output_dir)\n",
    "output_dirs.sort()\n",
    "output_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, select the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_dirs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, 'settings.pickle'),'rb') as set_file:\n",
    "    settings = pickle.load(set_file)\n",
    "settings    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = settings['dataset']\n",
    "# Register the dataset to detectron2\n",
    "for d in ['train', 'valid', 'test']:\n",
    "    DatasetCatalog.register('plankton_' + d, lambda d=d: training_functions.my_dataset_function(os.path.join(data_dir, d)))\n",
    "    MetadataCatalog.get('plankton_' + d).set(thing_classes=['plankton'])\n",
    "plankton_metadata = MetadataCatalog.get('plankton_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at a few training frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = training_functions.format_bbox(os.path.join(data_dir, 'train')) \n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d['file_name'])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=plankton_metadata, scale=1)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = []\n",
    "with open(os.path.join(output_dir, 'metrics.json'), 'r') as f:\n",
    "    for line in f:\n",
    "        training_metrics.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training and validation loss evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(\n",
    "    [m['iteration'] for m in training_metrics if 'total_loss' in m], \n",
    "    [m['total_loss'] for m in training_metrics if 'total_loss' in m]\n",
    ")\n",
    "plt.plot(\n",
    "    [m['iteration'] for m in training_metrics if 'validation_loss' in m], \n",
    "    [m['validation_loss'] for m in training_metrics if 'validation_loss' in m])\n",
    "plt.legend(['total_loss', 'validation_loss'], loc='best')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(\n",
    "    [m['iteration'] for m in training_metrics if 'total_loss' in m], \n",
    "    [m['total_loss'] for m in training_metrics if 'total_loss' in m]\n",
    ")\n",
    "plt.plot(\n",
    "    [m['iteration'] for m in training_metrics if 'validation_loss' in m], \n",
    "    [m['validation_loss'] for m in training_metrics if 'validation_loss' in m])\n",
    "plt.legend(['total_loss', 'validation_loss'], loc='best')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylim([min(plt.ylim()),0.45])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, 'test_results.pickle'),'rb') as results_file:\n",
    "    results = pickle.load(results_file)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at a few predicted frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model with default predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default config\n",
    "cfg = get_cfg()\n",
    "# Load training config\n",
    "cfg.merge_from_file(os.path.join(output_dir, 'my_cfg.yaml'))\n",
    "# Set detection threshold (can be played with)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = settings['test_threshold']\n",
    "# Load model weights\n",
    "cfg.MODEL.WEIGHTS = os.path.join(output_dir, 'model_final.pth')\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_dicts = training_functions.format_bbox(os.path.join(data_dir, 'test'))\n",
    "for d in random.sample(test_dataset_dicts, 10):\n",
    "    im = cv2.imread(d['file_name'])\n",
    "    outputs = predictor(im)\n",
    "    v = my_visualizer.Visualizer(im[:, :, ::-1],\n",
    "                   metadata=plankton_metadata, \n",
    "                   scale=1\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs['instances'].to('cpu'))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(v.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
